{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CuuBAcanPKvw"
   },
   "outputs": [],
   "source": [
    "# Import necessary Python libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRQyh_JQsyQT"
   },
   "source": [
    "## 1.Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lu3SIyO_PVeW",
    "outputId": "33bf50d0-d9e0-4028-9a53-32db8aea10f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining NaNs per column:\n",
      " City                    0\n",
      "Date                    0\n",
      "RentHousePrice_Ratio    0\n",
      "Mortgage                0\n",
      "Crime_Rate              0\n",
      "Unemployment_Rate       0\n",
      "MortgagePay_PerMonth    0\n",
      "School_Search_Number    0\n",
      "Housing_Price_Cut       0\n",
      "Building_Permits        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load and clean the dataset\n",
    "df = pd.read_excel('final_housing.xlsx', sheet_name=\"Data\")\n",
    "# Fill missing values with column means\n",
    "df_filled = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "# Check for any remaining NaNs\n",
    "print(\"Remaining NaNs per column:\\n\", df_filled.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-YWdM7cQAQH",
    "outputId": "7e3830c6-5c43-4903-85a5-5f2985a71a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1050 entries, 0 to 1049\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   City                  1050 non-null   object        \n",
      " 1   Date                  1050 non-null   datetime64[ns]\n",
      " 2   RentHousePrice_Ratio  1050 non-null   float64       \n",
      " 3   Mortgage              1050 non-null   float64       \n",
      " 4   Crime_Rate            1050 non-null   float64       \n",
      " 5   Unemployment_Rate     1042 non-null   float64       \n",
      " 6   MortgagePay_PerMonth  1050 non-null   float64       \n",
      " 7   School_Search_Number  1050 non-null   int64         \n",
      " 8   Housing_Price_Cut     840 non-null    float64       \n",
      " 9   Building_Permits      1050 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(7), int64(1), object(1)\n",
      "memory usage: 82.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KywSAN_4syQX",
    "outputId": "5e3253b4-1ea3-4654-e121-33999a92c2cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n"
     ]
    }
   ],
   "source": [
    "print(df['Housing_Price_Cut'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cnf-_o3ssyQY"
   },
   "outputs": [],
   "source": [
    "df_filled['Housing_Price_Cut'] = df_filled['Housing_Price_Cut'].fillna(df_filled['Housing_Price_Cut'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJOY2zgbQQQK",
    "outputId": "f6825976-92f2-45f1-d339-ab80eb25e9e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              City       Date  RentHousePrice_Ratio  Mortgage  Crime_Rate  \\\n",
      "0  Los Angeles, CA 2016-06-30              0.005120      3.66       737.0   \n",
      "1  Los Angeles, CA 2016-07-31              0.005136      3.41       737.0   \n",
      "2  Los Angeles, CA 2016-08-31              0.005184      3.43       737.0   \n",
      "3  Los Angeles, CA 2016-09-30              0.005261      3.46       737.0   \n",
      "4  Los Angeles, CA 2016-10-31              0.005318      3.42       737.0   \n",
      "\n",
      "   Unemployment_Rate  MortgagePay_PerMonth  School_Search_Number  \\\n",
      "0                5.5           2691.238403                    81   \n",
      "1                5.8           2663.114359                    75   \n",
      "2                5.7           2645.850984                    81   \n",
      "3                5.6           2621.161649                    79   \n",
      "4                5.3           2601.993478                    76   \n",
      "\n",
      "   Housing_Price_Cut  Building_Permits  \n",
      "0            0.17463       2741.433193  \n",
      "1            0.17463       2371.246447  \n",
      "2            0.17463       3337.256446  \n",
      "3            0.17463       2476.131833  \n",
      "4            0.17463       2756.962307  \n",
      "              City       Date  RentHousePrice_Ratio  Mortgage  Crime_Rate  \\\n",
      "1045  Stockton, CA 2024-10-31              0.002560      6.12       763.2   \n",
      "1046  Stockton, CA 2024-11-30              0.002549      6.79       763.2   \n",
      "1047  Stockton, CA 2024-12-31              0.002539      6.69       763.2   \n",
      "1048  Stockton, CA 2025-01-31              0.002542      6.91       762.0   \n",
      "1049  Stockton, CA 2025-02-28              0.002559      6.89       762.0   \n",
      "\n",
      "      Unemployment_Rate  MortgagePay_PerMonth  School_Search_Number  \\\n",
      "1045           6.700000           3402.963671                    15   \n",
      "1046           6.700000           3515.408402                    12   \n",
      "1047           6.700000           3496.897827                    13   \n",
      "1048           5.048081           3570.449086                    13   \n",
      "1049           5.048081           3533.983102                    17   \n",
      "\n",
      "      Housing_Price_Cut  Building_Permits  \n",
      "1045           0.261787        290.282532  \n",
      "1046           0.254968        204.291755  \n",
      "1047           0.216445        499.345215  \n",
      "1048           0.204837        273.335198  \n",
      "1049           0.211805        223.630969  \n",
      "City                            object\n",
      "Date                    datetime64[ns]\n",
      "RentHousePrice_Ratio           float64\n",
      "Mortgage                       float64\n",
      "Crime_Rate                     float64\n",
      "Unemployment_Rate              float64\n",
      "MortgagePay_PerMonth           float64\n",
      "School_Search_Number             int64\n",
      "Housing_Price_Cut              float64\n",
      "Building_Permits               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_filled.head())     # First 5 rows\n",
    "print(df_filled.tail())     # Last 5 rows\n",
    "print(df_filled.dtypes)     # Data types of columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKL5TxXvsyQY"
   },
   "source": [
    "## 2.EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "mNJ9-7VngrE7",
    "outputId": "cdb332fa-f197-4cce-abc8-d19d31df919a"
   },
   "outputs": [],
   "source": [
    "# Density plot for Rent / House Price\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.kdeplot(df_filled['RentHousePrice_Ratio'], fill=True, color='skyblue', linewidth=2)\n",
    "plt.title('Density Plot: Rent / House Price Ratio')\n",
    "plt.xlabel('Rent / House Price')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3iSkxTPaikER",
    "outputId": "32167645-d585-43b1-f7cf-9dbdfebb39ab"
   },
   "outputs": [],
   "source": [
    "# Select numeric data\n",
    "df_numeric = df_filled.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate layout\n",
    "num_vars = df_numeric.shape[1]\n",
    "cols = 3\n",
    "rows = int(np.ceil(num_vars / cols))\n",
    "\n",
    "# Plot all histograms\n",
    "df_numeric.hist(bins=20, figsize=(15, 5 * rows), layout=(rows, cols), edgecolor='black')\n",
    "plt.suptitle(\"Histograms for All Numeric Variables\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2DeF6tNvgzjU",
    "outputId": "b1deb1f0-8b0c-4fff-84a2-1f7a685358f8"
   },
   "outputs": [],
   "source": [
    "# Density plots for all numeric features\n",
    "# Select only numeric columns for density plot\n",
    "df_numeric = df_filled.select_dtypes(include=[np.number])\n",
    "\n",
    "# Automatically calculate layout\n",
    "n_vars = len(df_numeric.columns)\n",
    "cols = 3\n",
    "rows = int(np.ceil(n_vars / cols))\n",
    "\n",
    "# Plot\n",
    "df_numeric.plot(kind='density', subplots=True, layout=(rows, cols), figsize=(15, 5 * rows), sharex=False)\n",
    "plt.suptitle(\"Density Plots for Numeric Variables\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "Osp2cNlJQkbP",
    "outputId": "810a492f-c656-4c0a-c55c-618ca05f6242"
   },
   "outputs": [],
   "source": [
    "df_filled.set_index('Date')['RentHousePrice_Ratio'].plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4wRy8EnsyQa"
   },
   "source": [
    "## 3.Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "s2kiSykhsyQa",
    "outputId": "65b3faae-fd70-4e6c-df14-721b9b4ef005"
   },
   "outputs": [],
   "source": [
    "df_filled[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_aewv6ZesyQa",
    "outputId": "eacaaabd-75c5-4218-942b-24fb558336b1"
   },
   "outputs": [],
   "source": [
    "column_names = df.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "raR0ww1lsyQa",
    "outputId": "f6b5f8bc-230a-48cc-e5a2-a82f0bd35af0"
   },
   "outputs": [],
   "source": [
    "df_corr = df_filled[['Mortgage','Crime_Rate', 'Unemployment_Rate','School_Search_Number','Housing_Price_Cut','Building_Permits','RentHousePrice_Ratio']]\n",
    "\n",
    "df_corr[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J01eGhjmsyQa"
   },
   "source": [
    "### MultiCollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "id": "LPYAyju8syQa",
    "outputId": "b7dba1bc-9607-4fee-8e5f-bde280b0210b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# If X_scaled is a numpy array, convert it back to a DataFrame\n",
    "\n",
    "\n",
    "X_df = pd.DataFrame(df_corr, columns=df_corr.columns)\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = X_df.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PL2Dhd3DsyQa"
   },
   "outputs": [],
   "source": [
    "# everything except target\n",
    "y = df_filled['RentHousePrice_Ratio']\n",
    "X = df_filled.drop(columns=['Date','RentHousePrice_Ratio','MortgagePay_PerMonth','City'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "1.Mortgage vs Unemployment_Rate: There's a moderate negative correlation (-0.32), indicating that areas with higher unemployment tend to have lower mortgage values—possibly due to reduced purchasing power or loan eligibility.\n",
    "\n",
    "2.Building_Permits vs RentHousePrice_Ratio: There is a moderate positive correlation (0.38), suggesting that as more building permits are issued (indicating construction activity), the rent-to-price ratio tends to increase—possibly because new developments may target rental markets first.\n",
    "\n",
    "3.School_Search_Number vs Crime_Rate: A moderate positive correlation (0.38) exists, which may indicate that in areas with higher crime rates, people are more actively searching for schools—perhaps looking for safer or better school districts.\n",
    "\n",
    "4.Housing_Price_Cut vs Mortgage: There's a moderate positive correlation (0.36), which could imply that areas with more mortgage activity also see more frequent price cuts, potentially reflecting buyer negotiation or market corrections.\n",
    "\n",
    "5.RentHousePrice_Ratio shows weak correlations: It has very low correlations with most variables (all around ±0.01 to 0.38), suggesting that the rent-to-house-price ratio is influenced by multiple smaller factors or other external variables not shown in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-hnxqGNsyQb"
   },
   "source": [
    "## 5.Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xWNcPOpsyQb"
   },
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciwzE0MCsyQb",
    "outputId": "d57fc769-4661-4997-b185-b3c4c709dd7e"
   },
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSIW9WJJsyQb",
    "outputId": "27624a61-f872-4922-ca6a-46c9ed61abf1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 1. Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 2. Scale only X\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. Train the model (no scaling y)\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Predict (on scaled X_test)\n",
    "y_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# 5. Evaluate using original y_test\n",
    "lr_score = lr_model.score(X_test_scaled, y_test)\n",
    "\n",
    "# Calculate errors\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# 6. Print results\n",
    "print(f\"R² score on test set: {lr_score:.4f}\")\n",
    "print(f\"MAE: {mae:.10f}\")\n",
    "print(f\"MSE: {mse:.10f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8yeAP0IsyQb",
    "outputId": "dd50086b-90f6-4096-cd07-db7a9475bf52"
   },
   "outputs": [],
   "source": [
    "lr_coefficients = pd.Series(lr_model.coef_, index=X.columns)\n",
    "print(f\"R² score on test set: {lr_score:.4f}\") # Closer to 1 is better\n",
    "print(\"Linear Regression Coefficients:\") # A positive coefficient means that as the independent variable increases, the ratio tends to increase\n",
    "print(lr_coefficients) # A negative coefficient means that the variable has an inverse relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "v6NHcahpsyQb",
    "outputId": "8a58b037-31cb-4925-80b6-c25a694fe0da"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bPbTcSasyQb",
    "outputId": "c8d92032-a8fe-4234-befb-e73a310b316d"
   },
   "outputs": [],
   "source": [
    "# 1. Get intercept\n",
    "intercept = lr_model.intercept_\n",
    "\n",
    "# 2. Get coefficients with feature names\n",
    "coefficients = pd.Series(lr_model.coef_, index=X.columns)\n",
    "\n",
    "# 3. Print the regression equation\n",
    "print(f\"Linear Regression Equation:\\n\")\n",
    "\n",
    "equation = f\"y = {intercept:.6f}\"\n",
    "\n",
    "for feature, coef in coefficients.items():\n",
    "    if coef >= 0:\n",
    "        equation += f\" + {coef:.6f}*{feature}\"\n",
    "    else:\n",
    "        equation += f\" - {abs(coef):.6f}*{feature}\"\n",
    "\n",
    "print(equation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tGNXCWYuyKu8",
    "outputId": "466b6998-ce7c-4c10-873d-3927553753f2"
   },
   "outputs": [],
   "source": [
    "# 2. Display the correlation table\n",
    "print(\"Correlation Matrix:\\n\")\n",
    "print(corr_matrix)\n",
    "\n",
    "# 3. Optionally round and sort by correlation with the target variable\n",
    "target = 'RentHousePrice_Ratio'\n",
    "correlation_with_target = corr_matrix[target].sort_values(ascending=False)\n",
    "print(\"\\nCorrelation of features with RentHousePrice_Ratio:\")\n",
    "print(correlation_with_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation:\n",
    "Low R² Score (0.1781):\n",
    "Your model explains only 17.8% of the variance in the target variable (RentHousePrice_Ratio). This means most of the variation is still unaccounted for—indicating a weak model fit.\n",
    "\n",
    "Error Metrics:\n",
    "\n",
    "MAE (0.00053): On average, your model's predictions are off by about 0.00053, which may seem small, but relative to the prediction scale (~0.004), it’s significant.\n",
    "\n",
    "MSE (0.00000043): Squared errors are low, but this is expected with a small target value range.\n",
    "\n",
    "Actual vs Predicted Scatter Plot:\n",
    "\n",
    "There is a general upward trend, but the points are widely scattered, showing inconsistent prediction accuracy.\n",
    "\n",
    "Your model is struggling to align predictions closely with actual values, especially at higher target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVeKINkKzjcX",
    "outputId": "0cb03ed6-5809-4b4d-8827-2b4b3876bfac"
   },
   "outputs": [],
   "source": [
    "# OLS regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assume X and y are already defined as:\n",
    "# y = df['RentHousePrice_Ratio']\n",
    "# X = df[['Schools', 'Jobs', 'Business']] or any variables you choose\n",
    "\n",
    "# Add a constant (intercept term)\n",
    "X_sm = sm.add_constant(X)\n",
    "\n",
    "# Fit the OLS model\n",
    "model = sm.OLS(y, X_sm).fit()\n",
    "\n",
    "# Print the summary table (like in your image)\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEVaFUcvsyQb",
    "outputId": "76950c5a-399e-4a97-ef52-44a6a3defcca"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lr_model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "print(\"Cross-validation R² scores:\", scores)\n",
    "print(\"Average CV R²:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tg1KZ2qsyQc"
   },
   "source": [
    "## Interpretations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BcrxzHWsyQc"
   },
   "source": [
    "1.The model explains only 16.7% of the variation in the rent-to-house-price ratio, indicating a weak linear relationship.\n",
    "\n",
    "2.All variables are statistically significant, with Building_Permits having the strongest positive effect and Mortgage and Crime_Rate having negative effects.\n",
    "\n",
    "3.The high condition number (28,900) suggests possible multicollinearity among the predictors, which could affect the stability of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObWvAyN7syQc"
   },
   "source": [
    "## 6.K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "id": "ekrOJAH4RFal",
    "outputId": "c5657dc8-549a-49a9-8abf-72cb231ea5a4"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Scale the features (if not already scaled)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # Use full X, not just X_train\n",
    "\n",
    "# 2. Find the best k (number of clusters) using Elbow Method and Silhouette Score\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "k_values = range(2, 11)  # Test from 2 to 10 clusters\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, labels))\n",
    "\n",
    "# 3. Plot Inertia (Elbow curve)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(k_values, inertia, marker='o')\n",
    "plt.title('Elbow Method (Inertia vs k)')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 4. Plot Silhouette Scores\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(k_values, silhouette_scores, marker='o', color='orange')\n",
    "plt.title('Silhouette Score vs Number of clusters (k)')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQSYmozMsyQc"
   },
   "source": [
    "## HyperParameter Tuning - Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U41YCZkNsyQc",
    "outputId": "c3644472-0ea0-477c-e8b7-3fa63e8d723a"
   },
   "outputs": [],
   "source": [
    "# 5. Choose the best k manually based on plots (for example, k=3)\n",
    "optimal_k = 3\n",
    "# You can adjust this based on plots\n",
    "\n",
    "# 6. Final KMeans with the selected k\n",
    "final_kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "final_labels = final_kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# 7. Final silhouette score\n",
    "final_silhouette = silhouette_score(X_scaled, final_labels)\n",
    "\n",
    "print(f\"Final KMeans Model with k={optimal_k}\")\n",
    "print(f\"Final Silhouette Score: {final_silhouette:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kq7fFC2UsyQc"
   },
   "source": [
    "## Interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GA94weeXRpmE"
   },
   "source": [
    "lbow Plot Insight\n",
    "The elbow in the Inertia vs k graph appears around k=3 to 4, suggesting that 3 or 4 clusters is a good balance between compactness and simplicity. Beyond that point, the decrease in inertia slows down, meaning adding more clusters gives diminishing returns.\n",
    "\n",
    "Silhouette Score Insight\n",
    "The highest silhouette score (~0.256) occurs at k=6 and k=10, indicating that those clusterings have the best cohesion and separation. However, the silhouette score at k=3 (0.2289) is still acceptable, though not optimal.\n",
    "\n",
    "Final Model Choice (k=3)\n",
    "Using k=3 for the final KMeans model gives a moderate silhouette score, meaning the clusters are reasonably well-formed but not very distinct. This choice may prioritize interpretability or simplicity over accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHzPNEoOsyQd"
   },
   "source": [
    "## 7.Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fd3v5rKRF5x",
    "outputId": "fd6b81e8-e801-49a1-9ec3-79264808e067"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 1. Split dataset (use unscaled X and y first)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Scale features X\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. Scale target y\n",
    "y_train_scaled = y_train * 1000\n",
    "y_test_scaled = y_test * 1000\n",
    "\n",
    "# 4. Train Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# 5. Predict\n",
    "y_pred_scaled = rf.predict(X_test_scaled)\n",
    "\n",
    "# 6. Rescale predictions back\n",
    "y_pred = y_pred_scaled / 1000  # <-- Important to bring it back to real-world scale\n",
    "\n",
    "# 7. Evaluate model\n",
    "r2 = r2_score(y_test, y_pred)  # use original y_test (not scaled)\n",
    "rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "\n",
    "# 8. Print results\n",
    "print(f\"Random Forest R² Score: {r2:.4f}\")\n",
    "print(f\"Random Forest RMSE: {rmse:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "tH4K0J45SvWh",
    "outputId": "b1f73705-2f11-432f-a744-6d4d23f32b62",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances, y=features)\n",
    "plt.title(\"Random Forest Feature Importances\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weWqmFvzsyQd"
   },
   "source": [
    "### HyperParameter Tuning - Choosing the best estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLLcqH-v69LL",
    "outputId": "a002c7dd-2db8-4615-b3ac-32ab55f638a8"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define corrected parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']  # Removed 'auto'\n",
    "}\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                           cv=5, scoring='r2', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use best model to predict\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Manual RMSE\n",
    "\n",
    "print(f\"Tuned Random Forest R² Score: {r2:.4f}\")\n",
    "print(f\"Tuned Random Forest RMSE: {rmse:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtom8lrfsyQi"
   },
   "source": [
    "### Interpretation\n",
    "\n",
    "Model Performance\n",
    "The Tuned Random Forest model performs extremely well with an R² score of 0.9304, meaning it explains over 93% of the variance in the rent-to-house-price ratio. The low RMSE (0.000192) indicates high prediction accuracy.\n",
    "\n",
    "Most Important Feature\n",
    "Crime_Rate is by far the most influential variable in the model, showing the highest feature importance. This suggests that areas with differing crime levels play a critical role in determining rent returns relative to house prices.\n",
    "\n",
    "Other Influential Features\n",
    "Schools and Unemployment_Rate also contribute significantly, while Mortgage and Housing_Price_Cut have minimal influence on the model’s predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gRVpDG5syQi"
   },
   "source": [
    "## 8.PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "Cgv82MIPTlFO",
    "outputId": "4ded25e5-dfa6-4da1-d597-e97782e0723a"
   },
   "outputs": [],
   "source": [
    "# PCA Analysis\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Fit PCA on standardized data\n",
    "\n",
    "pca = PCA(n_components=0.95)  # retain 95% variance\n",
    "X_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "# Explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(\"PCA Explained Variance Ratio per Component:\")\n",
    "print(explained_variance)\n",
    "\n",
    "# Optional: Scree plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=list(range(1, len(explained_variance) + 1)), y=explained_variance)\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel(\"Explained Variance Ratio\")\n",
    "plt.title(\"Scree Plot: PCA Components\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFdEoZI9n432"
   },
   "source": [
    "Top 2 Components Explain Over Half the Variance\n",
    "The first two principal components together explain approximately 55.3% of the total variance (0.2891 + 0.2642), making them the most informative dimensions.\n",
    "\n",
    "Diminishing Returns After PC3\n",
    "The explained variance drops notably after the third component. PC3 adds another ~17.3%, but later components contribute less (under 11% each), suggesting reduced informational value.\n",
    "\n",
    "Dimensionality Reduction Opportunity\n",
    "You could reduce the dataset to 3 or 4 principal components while retaining a majority (over 83%) of the data’s variability, which can improve efficiency without major information loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
